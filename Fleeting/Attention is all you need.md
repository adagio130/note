![[Pasted image 20240326135310.png]]
1. Self Attention
2. Multi-Head Attention
3. Position Encoding
4. Encoder
5. Decoder
6. Feed-Forward Networks
7. Layer Normalization and Residual Connection

steps:

1. tokenize (斷詞)
2. using pre-train model to convert to vector
3. add special annotation such as \[CLS\]、\[SEP\]